{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: PCA\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "* Working with images using scikit-image\n",
    "* PCA using scikit-learn\n",
    "* Practical applications of PCA\n",
    "\n",
    "## Setup\n",
    "\n",
    "* Download [Anaconda Python 3.6](https://www.anaconda.com/download/) for consistent environment.\n",
    "* If you use pip environment then make sure your code is compatible with versions of libraries provided withing Anaconda's Python 3.6 distribution.\n",
    "\n",
    "## Submission\n",
    "* Do not change any variable/function names.\n",
    "* Just add your own code and don't change existing code\n",
    "* Save this file and rename it to be **studentid_lastname.ipynb** (student id (underscore) last name.ipynb) where your student id is all numbers.\n",
    "* Submit only single .ipynb file to learn (no zip or .py files or anything else)\n",
    "* If you happen to use any external library not included in Anaconda (mention in **Submission Notes** section below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Notes\n",
    "(Please write any notes here that you think I should know during marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NO MARKS] PCA Warming Up (MUST READ)\n",
    "\n",
    "I'm adding some code to illustrate examples of PCA using sklearn library.\n",
    "\n",
    "**Let's create some random `5d` data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 100 points of 5d data\n",
    "data = np.random.rand(100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets convert this `5d` data to `2d` using PCA`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.decomposition.pca.PCA"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_components=2 because I want to convert 5d data to 2d (dimensionality reduction)\n",
    "pca = PCA(n_components=2)\n",
    "type(pca.fit(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In code above when we call `fit`, it populates two things in `pca`:\n",
    "1. `mean_`\n",
    "2. `components_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48879699, 0.47259135, 0.47862106, 0.51663741, 0.50168923])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of the input data (per dimension) used to zeroying the mean\n",
    "pca.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72189596, -0.18179047,  0.6544353 ,  0.10740589, -0.07743939],\n",
       "       [ 0.42159063,  0.39389331,  0.65021876, -0.4924353 , -0.04280711]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basis vectors\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to transform `5d` from `data` into `2d` using following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_reduce = data[:10]\n",
    "reduced_data = np.dot(data_to_reduce - pca.mean_, pca.components_.T)\n",
    "\n",
    "# reduced data from 5d to 2d\n",
    "reduced_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can accomplish the same using `transform` function provided in `pca`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(data_to_reduce).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for inverse transform or changing `2d` data back to `5d`\n",
    "\n",
    "Compression --> Decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08349581, 0.29138987, 0.56209011, 0.69512774, 0.48242422],\n",
       "       [0.57758734, 0.6024743 , 0.78394024, 0.34284448, 0.4783164 ],\n",
       "       [0.65992359, 0.49808721, 0.26034203, 0.51745845, 0.52543055],\n",
       "       [0.4164784 , 0.39473152, 0.33015345, 0.6164798 , 0.51218127],\n",
       "       [0.55785116, 0.50108614, 0.4558677 , 0.48977792, 0.50569907],\n",
       "       [0.53356538, 0.55262151, 0.68474581, 0.40729137, 0.48545512],\n",
       "       [0.1689473 , 0.42482553, 0.8862008 , 0.51527002, 0.457349  ],\n",
       "       [0.50990578, 0.48420339, 0.48207723, 0.50409341, 0.5020272 ],\n",
       "       [0.63450995, 0.55091822, 0.49591072, 0.43278053, 0.5045823 ],\n",
       "       [0.38790961, 0.32053905, 0.11565184, 0.72078973, 0.5296152 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompressed_data = np.dot(reduced_data, pca.components_)+pca.mean_\n",
    "decompressed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08349581, 0.29138987, 0.56209011, 0.69512774, 0.48242422],\n",
       "       [0.57758734, 0.6024743 , 0.78394024, 0.34284448, 0.4783164 ],\n",
       "       [0.65992359, 0.49808721, 0.26034203, 0.51745845, 0.52543055],\n",
       "       [0.4164784 , 0.39473152, 0.33015345, 0.6164798 , 0.51218127],\n",
       "       [0.55785116, 0.50108614, 0.4558677 , 0.48977792, 0.50569907],\n",
       "       [0.53356538, 0.55262151, 0.68474581, 0.40729137, 0.48545512],\n",
       "       [0.1689473 , 0.42482553, 0.8862008 , 0.51527002, 0.457349  ],\n",
       "       [0.50990578, 0.48420339, 0.48207723, 0.50409341, 0.5020272 ],\n",
       "       [0.63450995, 0.55091822, 0.49591072, 0.43278053, 0.5045823 ],\n",
       "       [0.38790961, 0.32053905, 0.11565184, 0.72078973, 0.5296152 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same can we accomplished using inverse_transform\n",
    "pca.inverse_transform(pca.transform(data_to_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15513916077888032"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets find compression decompression error (absolute mean error)\n",
    "np.sum(np.abs(data_to_reduce - decompressed_data))/data_to_reduce.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks [100 marks]\n",
    "\n",
    "### Task 1: Building an Image Compression Algorithm\n",
    "\n",
    "In this section you will build you own compression algorithm for images using PCA.\n",
    "\n",
    "**STEP 1: Read the image**\n",
    "1. Use `imread` function from `skimage.io` to read `leena.jpg`.\n",
    "2. Show the image using `show_image` function provided to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dfd3fbd44634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# image = ....\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# plt.figure(figsize=(10, 10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# make matplotlib to show plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "def show_image(img):\n",
    "    if len(img.shape) == 2:\n",
    "        plt.imshow(img, cmap='Greys_r')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image Dimension: {0},{1}'.format(img.shape[0], img.shape[1]), fontsize=20)\n",
    "    \n",
    "# !!ADD CODE HERE!!\n",
    "# image = ....\n",
    "# plt.figure(figsize=(10, 10))\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2: Compressing an image using PCA**\n",
    "\n",
    "Image is generally made of 3 (or 4) channels (RGB), we will build a compression algorithm that applies one channel at a time to compress multi-channel image.\n",
    "\n",
    "In order to compress entire image you will compress all the channels within the image one by one and then serialize compressed channels and any auxiliary data required for decompression (for ex. principle components (components\\_), means (means\\_), original image size).\n",
    "\n",
    "In order to decompress, you will deserialize the data, then uncompress the compressed channel one by one and stack them up to rebuild the uncompressed version of the original image. \n",
    "\n",
    "\n",
    "**Compression Strategy using PCA**\n",
    "\n",
    "- The above image you have read is of size `350 x 780`, i.e. width is `780` and height is `350`\n",
    "- Patch the image into `10x10` patches yielding `35x78=2730` patches in total.\n",
    "- Flatten each patch `(10x10)` into `100` dimensional vector.\n",
    "- Now (for each channel) you will have `2730` number of `100-d` vectors.\n",
    "- Apply PCA on these vectors.\n",
    "- Reduce the dimensionality of `100-d` vector to `5-d`.\n",
    "\n",
    "I've given you two functions `patchify` and `depatchify`. \n",
    "\n",
    "`patchify` creates `100-d` vectors from all the patches from a given image and `depatchify` combines these `100-d` patches back to the image of the given size.\n",
    "\n",
    "Please read through code below and figure out how these two functions work.\n",
    "\n",
    "**NOTE**: `convert_to_cf` is important function to note (in cell below). It converts channel last format image to channel first format. Images that you read through `imread` function returns array of shape `X x Y x 3` channel is last axis, it is easier if channel were first axis then to extract any channel you can do use first indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def patchify(img, ps=(10, 10)):\n",
    "    patches = []\n",
    "    h, w = img.shape\n",
    "    for i in range(0, h, ps[0]):\n",
    "        for j in range(0, w, ps[1]):\n",
    "            patches.append(img[i:i+ps[0], j:j+ps[1]].ravel()) \n",
    "    return np.array(patches)\n",
    "\n",
    "\n",
    "def depatchify(patches, patch_size=(10, 10), img_size=(350, 780)):\n",
    "    # normalize\n",
    "    patches[patches > 255.] = 255.\n",
    "    patches[patches < 0.] = 0.\n",
    "    \n",
    "    # convert to unint8\n",
    "    patches = patches.astype('uint8')\n",
    "    rec_img = np.zeros(img_size, dtype='uint8')\n",
    "    ph, pw = patch_size\n",
    "    \n",
    "    h, w = img_size\n",
    "    x = 0\n",
    "    for i in range(0, h, ph):\n",
    "        for j in range(0, w, pw):\n",
    "            rec_img[i:i+ph, j:j+pw] = patches[x].reshape((ph, pw))\n",
    "            x += 1\n",
    "            \n",
    "    return rec_img\n",
    "\n",
    "def convert_to_cf(img_cl):\n",
    "    # convert image to channel first\n",
    "    img_cf = np.swapaxes(img_cl.T, 1, 2)\n",
    "    return img_cf\n",
    "\n",
    "image=imread('leena.jpg')\n",
    "img_cf = convert_to_cf(image)\n",
    "\n",
    "# I'll patchify each channel and depatchify them\n",
    "# Then I'll stack them together to create original image back\n",
    "ch1 = depatchify(patchify(img_cf[0])) # first channel\n",
    "ch2 = depatchify(patchify(img_cf[1])) # second channel\n",
    "ch3 = depatchify(patchify(img_cf[2])) # third channel\n",
    "\n",
    "# combine them now\n",
    "rec_img = np.dstack((ch1, ch2, ch3))\n",
    "plt.figure(figsize=(12, 12))\n",
    "show_image(rec_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3: Compressing single channel of an image (FILL TWO FUNCTIONS BELOW)**\n",
    "\n",
    "Now you are familiar with how `patchify` and `depatchify` work. Do the following:\n",
    "\n",
    "1. Write a function `compress` that will take one of the channel of the image as input and outputs compressed channel and auxiliary data required for decompressing. Return type of this function should be dictionary.\n",
    "2. Write another function `decompress` that will take whatever dictionary data you returned from previous `compress` function and decompresses it into image channel (that was compressed).\n",
    "3. PCA compression is lossy compression algorithm -- means you will loose the information during decompression.\n",
    "4. I should be able to call two of your functions like so `decompress(compress(img_ch[0]))` to compress and decompress the given image's channel.\n",
    "\n",
    "**Compress: Pseudo code**\n",
    "- `Patchify` the given image's channel (input).\n",
    "- Run `PCA` on the patches (you may use sklearn's implementation) to reduce them to `5d` vectors.\n",
    "- You will need `basis vectors` or `principal components` and `mean` in order to reconstruct the data back to `100d`\n",
    "- Return dictionary: `{'compressed_patches': 5d vectors, 'aux_data': principal components/basis vectors/means/final size of image}`\n",
    "- By converting `100d` to `5d`, you reduce size by `20` times.\n",
    "\n",
    "**Decompress: Pseudo code**\n",
    "- Input is dictionary as returned by your `compress` function.\n",
    "- Use `5d` vectors and do inverse PCA (check tutorial 2) and convert them back to `100d` vectors.\n",
    "- Use `depatchify` function to convert these reconstructed `100d` vectors into an image channel\n",
    "\n",
    "**Tip**:  Good code is always modular and easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE FOLLOWING FUNCTIONS\n",
    "\n",
    "def compress(img_ch, n_components=5):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        img_ch: one of the channel of given image\n",
    "        n_components: number of components returned by PCA\n",
    "    Returns\n",
    "        comp_data: Some data structure (may be dict.) that represents compressed form of given input\n",
    "        along with auxiliary data required for decompression (components_, mean_ and shape of input image)\n",
    "    \"\"\"\n",
    "    # patchify img_ch\n",
    "    patches = patchify(img_ch)\n",
    "    # pca = PCA(n_components=n_components)\n",
    "    # y = pca.fit_transform(patches)\n",
    "    \n",
    "    # apply PCA with n=n_components on the patches\n",
    "    # return dictionary {'y': compressed data, 'aux_data': auxiliary data for recontruction}\n",
    "    pass\n",
    "\n",
    "def decompress(comp_data):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        comp_data: data structure that is returned by `compress` function\n",
    "    Returns\n",
    "        img_ch: decompressed form of channel compressed and contained inside `comp_data` data structure\n",
    "    \"\"\"\n",
    "    #y = comp_data['y']\n",
    "    #components, means, img_size = comp_data['aux_data']\n",
    "    \n",
    "    # recontruct the patches to 100d using aux_data and inverse PCA\n",
    "    # depatchify and return img_ch\n",
    "    #rec_patches = inverse_transform(y, components, means)\n",
    "    img_ch = depatchify(rec_patches, img_size=img_size)\n",
    "    return img_ch\n",
    "\n",
    "# Red channel\n",
    "# visualize your compression and decompression\n",
    "img_ch = img_cf[0]\n",
    "plt.figure(figsize=(10, 10))\n",
    "show_image(img_ch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "show_image(decompress(compress(img_ch, n_components=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3: Compress and decompress entire image (FILL TWO MORE FUNCTIONS)**\n",
    "\n",
    "Write a `compress_image` function that:\n",
    "\n",
    "- takes `channel last` (regular image read from `imread`) representation of an image\n",
    "- convert `channel last` to `channel first` representation using `convert_to_cf` function defined previously\n",
    "- compresses each of the channel using `compress` function\n",
    "- outputs a one dictionary that contains all auxiliary data required to reconstruct/decompress entire image back.\n",
    "\n",
    "Similarly, write `decompress_image` function that:\n",
    "\n",
    "- decompresses the image compressed by `compress_image` function \n",
    "- return `channel last` image\n",
    "\n",
    "**NOTE:** You would patchify each channel and implement PCA on each channel thus for decompression you need `components_`, `mean_` for each channel and you need shape of input image as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_image(img):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        img_cf: `Channel last` image data\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def decompress_image(comp_img):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        img_rec: Decompressed `channel last` image\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(BONUS) STEP 4: Serialization and de-serialization**\n",
    "\n",
    "You can easily (de)serialize dictionary using `np.save` and `np.load` (see example below)\n",
    "\n",
    "`compress_and_serialize` should:\n",
    "- Read image given by `inp_path`\n",
    "- Use `compress_image` to compress it\n",
    "- Serialize the compressed data using `np.save` to a file specified by `out_path`\n",
    "\n",
    "**NOTE:** All the data required for deserialization must be saved to a one single file only.\n",
    "\n",
    "`deserialize_and_decompress` should:\n",
    "- Read the file specified by `inp_path` using `np.load`\n",
    "- Use `decompress_image` function to decompress it\n",
    "- Return image (channel last as returned by `decompress_image`) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE OF SAVING AND LOADING DICTIONARY OBJECT TO/FROM FILESYSTEM\n",
    "d = {'a': [1, 2, 3], 'b': [4, 5, 6, 7, 8]}\n",
    "np.save('example.npy', d)\n",
    "ds = np.load('example.npy').item()\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE THESE TWO FUNCTIONS\n",
    "def compress_and_serialize(inp_path='leena.jpg', out_path='output.bin'):\n",
    "    pass\n",
    "\n",
    "def deserialize_and_decompress(inp_path='output.bin'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(BONUS) STEP 5: What is size of output.bin file?**\n",
    "\n",
    "If you did **STEP 4** then proceed.\n",
    "\n",
    "Did you end of in compressing anything? Conclude your experiments!\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Write your conclusion here!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IF YOU DID STEP 4\n",
    "import os\n",
    "\n",
    "print('Original', os.path.getsize('leena.jpg'), 'bytes')\n",
    "print('Compressed', os.path.getsize('output.bin'), 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Rotation and Translation Invariance in PCA\n",
    "\n",
    "**STEP 1 (done already): Create normally distributed data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0, 0]\n",
    "cov = [[10, 10], [10, 40]]  # diagonal covariance\n",
    "x, y = np.random.multivariate_normal(mean, cov, 100).T\n",
    "X = np.array(list(zip(x, y)))\n",
    "\n",
    "def plot_data(X):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(X[:, 0], X[:, 1], 'ro')\n",
    "    plt.xlim([-20, 20])\n",
    "    plt.ylim([-20, 20])\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "    \n",
    "plot_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2: Rotate the data by 45 degrees and create new array X_rot**\n",
    "\n",
    "Write code to rotate X by 45\n",
    "\n",
    "- Use rotation matrix\n",
    "- Or individually rotate each point in `X` by 45 degrees\n",
    "- Use `plot_data` function defined in cell above to visualize the rotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.radians(45)\n",
    "# WRITE CODE HERE\n",
    "# Code to rotate X\n",
    "# populate new matrix X_rot\n",
    "plot_data(X_rot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3 (done but need explanation): Perform pca with n_components=2**\n",
    "\n",
    "Do you see anything interesting?\n",
    "\n",
    "Explain the code below and write down your observations (2-3 lines only).\n",
    "\n",
    "\n",
    "**Observations**\n",
    "\n",
    "WRITE YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def visualize_components(X, X_rot):\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    pca.fit(X)\n",
    "    df1 = pd.DataFrame(pca.fit_transform(X))\n",
    "    df2 = pd.DataFrame(pca.fit_transform(X_rot))\n",
    "\n",
    "    return pd.concat((df1, df2), axis=1)[:20]\n",
    "    \n",
    "visualize_components(X, X_rot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4: Perform PCA again and find angle between principal components**\n",
    "\n",
    "- Perform PCA on X and X_rot with n_components=1\n",
    "- It will give one basis vector for each of data (X and X_rot)\n",
    "- Find the angle between these two basis vectors\n",
    "- Explain your observations?\n",
    "\n",
    "**Observations**\n",
    "\n",
    "WRITE YOUR OBSERVATIONS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def angle_between(a,b):\n",
    "    # COMPLETE THIS FUNCTION\n",
    "    # CALCULATE ANGLE IN RAD BETWEEN TWO VECTORS\n",
    "    pass\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(X)\n",
    "c1 = pca.components_\n",
    "\n",
    "pca.fit(X_rot)\n",
    "c2 = pca.components_\n",
    "\n",
    "np.rad2deg(angle_between(c1[0], c2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(NO MARKS) STEP 5: Repeat these experiments for translation as well**\n",
    "\n",
    "There is not marks for this part. You can do this for your own learning.\n",
    "\n",
    "Now translate every point in `X` by fixed `x` and `y` amount.\n",
    "\n",
    "`X = X + [1, 2]`\n",
    "\n",
    "like so and repeat all the above experiments in cell below and write down your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM EXPERIMENTS WITH TRANSLATION HERE\n",
    "# NO MARKS FOR DOING THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Recovery of corrupted images using PCA\n",
    "\n",
    "Check the code below.\n",
    "\n",
    "It corrupts the `leena.jpg` image that you worked on before.\n",
    "\n",
    "Check very carefully what below code is doing on the image and answer:\n",
    "\n",
    "**Is it same as rotation of data points (like done before), if yes explain (just one liner)?**\n",
    "\n",
    "EXPLAIN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for corrupting the leena image\n",
    "image = convert_to_cf(imread('leena.jpg'))[0]\n",
    "\n",
    "def corrupt_image(img):\n",
    "    # lets patchify R channel with patches of 35x78 patches\n",
    "    patches = patchify(img)\n",
    "    \n",
    "    # Noise 1:\n",
    "    # lets jumble pixels of patches now\n",
    "    jumble_idx = list(range(len(patches[0])))\n",
    "    np.random.shuffle(jumble_idx)\n",
    "    \n",
    "    jumbled_patches = np.array([patch[jumble_idx] for patch in patches])\n",
    "    rec_jumbled_image = depatchify(jumbled_patches, img_size=img.shape)\n",
    "    \n",
    "    return rec_jumbled_image\n",
    "\n",
    "\n",
    "cimage = corrupt_image(image)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "show_image(image)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "show_image(cimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recovering from the corruption**\n",
    "\n",
    "Use the `compress` function you coded earlier to get compressed form of original leena image and corrupted leena image.\n",
    "\n",
    "We will try to recover the corrupted leena given the compressed version of original leena.\n",
    "\n",
    "Notice in code below, I replace `aux_data` of corrupted version with `aux_data` of original version.\n",
    "\n",
    "Does the code below code work in recovering the original leena image back?\n",
    "\n",
    "**Explain how below code works and show it actually works?**\n",
    "\n",
    "EXPLAIN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assuming your compress function returns dictionary which contains `aux_data`\n",
    "# if you coded your compress in diferent way then change code below appropriately\n",
    "# basically u need to replace auxiliary data of corrupted with original while keeping compressed (transformed) data same\n",
    "d = compress(image, n_components=50)\n",
    "d1 = compress(cimage1, n_components=50)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "show_image(decompress(d1))\n",
    "\n",
    "d1['aux_data'] = d['aux_data']\n",
    "plt.figure(figsize=(10, 10))\n",
    "show_image(decompress(d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Decrypting manuscript of the lost civilization\n",
    "\n",
    "You belong to one of the advanced civilization,  while exploring the universe you land on the planet Earth, however, there is no inhabitants on that planet anymore. While exploring the remains of \"humans\" on planet Earth, you come across some damaged hard drive that contains various images. You suspect that these images manuscript of how \"humans\" use to write different digits in maths. You recovered all the data from that hard drive safely. You opened up your jupyter notebook (python being universal language and popular among alien species), you started plotting the images you just recovered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rimages = np.load('recovered_images.npy')\n",
    "rimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_manuscript(images):\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(4, 5, i+1)\n",
    "        plt.imshow(img, cmap='Greys_r')\n",
    "        plt.axis('off')\n",
    "        \n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_manuscript(rimages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You being very smart, you figured out these images are encrypted and not in their original form. You also figured out that encryption is just fixed jumbling of the pixel of the images. Since you're unaware of manuscript, you cannot decrypt the images just by themselves even if they follow the fixed jumbling pattern. However, fortunately you have `principal components` and `mean` of the the original manuscript. Now, your task is to recover 20 images and plot them nicely in cell below.\n",
    "\n",
    "Use `plot_manuscript` function from above to plot the recovered manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_components = np.load('original_pca.npy')\n",
    "original_mean = np.load('original_mean.npy')\n",
    "\n",
    "# you have three data original_components, original_mean and rimages\n",
    "# `rimages` contains corrupted version of images from original manuscript\n",
    "# `original_components` contains principal components of images from the original manuscript\n",
    "# `original_mean` contains mean values of each dimension of the images from original manuscript\n",
    "# use all these things to recover/estimate images of the original manuscript containing 20 images\n",
    "# plot all those recovred 20 images from `plot_manuscript` function above"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/aff9e6e8ebaf9e733ae5b58405965b6b"
  },
  "gist": {
   "data": {
    "description": "projects/SYDE-522/Tutorials/Assignments/Assignment 1/Tutorial Assignment 1.ipynb",
    "public": false
   },
   "id": "aff9e6e8ebaf9e733ae5b58405965b6b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
